{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5l1XzKb2ti8-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn, optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SGD(nn.Module):\n",
        "  def __init__(self, params, lr, wd=0.1):\n",
        "    super().__init__()\n",
        "    self.params = list(params)\n",
        "    self.lr, self.wd = lr, wd\n",
        "    self.i = 0\n",
        "\n",
        "  def step(self):\n",
        "    with torch.no_grad():\n",
        "      for p in self.params:\n",
        "        self.reg_step(p)\n",
        "        self.opt_step(p)\n",
        "    self.i += 1\n",
        "\n",
        "  def opt_step(self, p): p -= p.grad * self.lr\n",
        "\n",
        "  def ref_step(self, p):\n",
        "    if self.wd != 0: self.p *= 1 - self.lr * self.wd\n",
        "\n",
        "  def zero_grad(self):\n",
        "    for p in self.params: p.grad.data.zero_()"
      ],
      "metadata": {
        "id": "sRCNHgq8U-V3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Momentum(SGD):\n",
        "  def __init__(self, params, lr, wd=0.1, mom=0.9):\n",
        "    super().__init__(params, lr=lr, wd=wd)\n",
        "    self.mom = mom\n",
        "\n",
        "  def opt_step(self, p):\n",
        "    if not hasattr(p, 'grad_avg'): p.grad_avg = torch.zeros_like(p.grad)\n",
        "    p.grad_avg = p.grad_avg * self.mom + p.grad * (1 - self.mom)\n",
        "    p -= self.lr * p.grad_avg"
      ],
      "metadata": {
        "id": "d-up0js7WW3i"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RMSProp(SGD):\n",
        "  def __init__(self, params, lr, wd=0.1, sqr_mom=0.99, eps=1e-5):\n",
        "    super().__init__(params, lr=lr, wd=wd)\n",
        "    self.sqr_mom, self.eps = sqr_mom, eps\n",
        "\n",
        "  def opt_step(self, p):\n",
        "    if not hasattr(p, 'sqr_avg'): p.sqr_avg = p.grad**2\n",
        "    p.sqr_avg = p.sqr_avg * self.sqr_mom + p.grad ** 2 * (1 - self.sqr_mom)\n",
        "    p -= self.lr * p.grad / (p.sqr_avg.sqrt() + self.eps)"
      ],
      "metadata": {
        "id": "xguM1lD0XX-8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Adam(SGD):\n",
        "    def __init__(self, params, lr, wd=0., beta1=0.9, beta2=0.99, eps=1e-5):\n",
        "        super().__init__(params, lr=lr, wd=wd)\n",
        "        self.beta1,self.beta2,self.eps = beta1,beta2,eps\n",
        "\n",
        "    def opt_step(self, p):\n",
        "        if not hasattr(p, 'avg'): p.avg = torch.zeros_like(p.grad.data)\n",
        "        if not hasattr(p, 'sqr_avg'): p.sqr_avg = torch.zeros_like(p.grad.data)\n",
        "        p.avg = self.beta1*p.avg + (1-self.beta1)*p.grad\n",
        "        unbias_avg = p.avg / (1 - (self.beta1**(self.i+1)))\n",
        "        p.sqr_avg = self.beta2*p.sqr_avg + (1-self.beta2)*(p.grad**2)\n",
        "        unbias_sqr_avg = p.sqr_avg / (1 - (self.beta2**(self.i+1)))\n",
        "        p -= self.lr * unbias_avg / (unbias_sqr_avg + self.eps).sqrt()"
      ],
      "metadata": {
        "id": "G6FMU7WVYyFc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pixTMBFUY36M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}