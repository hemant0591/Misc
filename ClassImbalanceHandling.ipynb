{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xcrIQb5-3IXg"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "ODCWgXAO5dfA"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Weighted CrossEntropy**"
      ],
      "metadata": {
        "id": "IpoVOgQU5sQV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from collections import Counter\n",
        "\n",
        "# Define probabilities for each class to introduce imbalance\n",
        "probabilities = torch.tensor([0.05, 0.05, 0.1, 0.1, 0.1, 0.1, 0.15, 0.15, 0.1, 0.1])\n",
        "\n",
        "# Generate labels based on the defined probabilities\n",
        "labels = torch.arange(10)\n",
        "data = torch.multinomial(probabilities, num_samples=10000, replacement=True).tolist()\n",
        "\n",
        "print(f\"Generated {len(data)} labels with class imbalance.\")\n",
        "print(f\"First 10 labels: {data[:10]}\")\n",
        "\n",
        "\n",
        "# Calculate class counts and weights\n",
        "counts = Counter(data)\n",
        "print(f\"Class counts: {counts}\")\n",
        "\n",
        "num_classes = max(labels) + 1\n",
        "freqs = torch.tensor([counts.get(i, 0) for i in range(num_classes)], dtype=torch.float32)\n",
        "weights = 1 / (freqs + 1e-5)\n",
        "\n",
        "weights = weights / weights.sum() * num_classes # normalize weights\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight=weights.to(device))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIPs07HW3QxD",
        "outputId": "140e61bf-a668-466d-f9c6-cf65c612c2cc"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated 10000 labels with class imbalance.\n",
            "First 10 labels: [9, 4, 4, 4, 7, 9, 7, 9, 6, 7]\n",
            "Class counts: Counter({6: 1523, 7: 1492, 8: 1037, 3: 1029, 9: 1026, 2: 982, 5: 970, 4: 945, 0: 505, 1: 491})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(weights), weights.mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "Gyga7Mjl3sMl",
        "outputId": "8e31e23d-0769-465f-c0c1-1cb05b980d31"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([1.7428, 1.7925, 0.8963, 0.8553, 0.9314, 0.9074, 0.5779, 0.5899, 0.8487,\n",
              "        0.8578])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, tensor(1.))"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Oversampling with WeightedRandomSampler**"
      ],
      "metadata": {
        "id": "WSIsxtkR5wH_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
        "\n",
        "# Calculate sample weights for each data point based on class frequencies\n",
        "sample_weights = [1.0 / counts[label] for label in data]\n",
        "\n",
        "\n",
        "sampler = WeightedRandomSampler(sample_weights, num_samples=len(data), replacement=True)\n",
        "\n",
        "# Assuming we have a train_dataset and collate_fn defined\n",
        "# train_loader = DataLoader(train_dataset, batch_size=8, sampler=sampler, collate_fn=collate_fn)\n",
        "\n",
        "print(f\"Length of data: {len(data)}\")\n",
        "print(f\"Length of sample_weights: {len(sample_weights)}\")\n",
        "print(f\"First 10 sample weights: {sample_weights[:10]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8w1Oj555VKx",
        "outputId": "2de45076-c8e7-4c48-ad41-cc6cb6cfd297"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of data: 10000\n",
            "Length of sample_weights: 10000\n",
            "First 10 sample weights: [0.0009746588693957114, 0.0010582010582010583, 0.0010582010582010583, 0.0010582010582010583, 0.0006702412868632708, 0.0009746588693957114, 0.0006702412868632708, 0.0009746588693957114, 0.0006565988181221273, 0.0006702412868632708]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AEGBslRN7uaV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}